{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Brain Tumor detection of Brain MRI images using VGG16 Deep Learning architecture ","metadata":{}},{"cell_type":"markdown","source":"**Importing necessary Libraries**","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tqdm as tqdm\nimport cv2 as cv\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D , MaxPooling2D ,GlobalAveragePooling2D ,Flatten , Dense , Dropout , BatchNormalization \nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nimport tensorflow as tf\ntf.keras.applications.VGG16\nfrom keras.applications.vgg16 import VGG16\nfrom keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\nfrom keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\nfrom keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:18.008791Z","iopub.execute_input":"2022-09-09T15:19:18.009448Z","iopub.status.idle":"2022-09-09T15:19:24.755016Z","shell.execute_reply.started":"2022-09-09T15:19:18.009355Z","shell.execute_reply":"2022-09-09T15:19:24.754189Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"converting categorical labels to numeric codes","metadata":{}},{"cell_type":"code","source":"encoder = OneHotEncoder()     #LabelEncoder encode labels with value between 0 and n_classes-1\nencoder.fit([[0],[1]])   ","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:31.367947Z","iopub.execute_input":"2022-09-09T15:19:31.368637Z","iopub.status.idle":"2022-09-09T15:19:31.382285Z","shell.execute_reply.started":"2022-09-09T15:19:31.368600Z","shell.execute_reply":"2022-09-09T15:19:31.381346Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**Loading the data**","metadata":{}},{"cell_type":"markdown","source":"Resizing the image based on input dimension required for the model","metadata":{}},{"cell_type":"code","source":"input_path = []\nlabel = []","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:31.384520Z","iopub.execute_input":"2022-09-09T15:19:31.384783Z","iopub.status.idle":"2022-09-09T15:19:31.388995Z","shell.execute_reply.started":"2022-09-09T15:19:31.384747Z","shell.execute_reply":"2022-09-09T15:19:31.388215Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = []\npaths = []\nresult = []\nfor r,d,f in os.walk(r\"../input/brain-mri-images-for-brain-tumor-detection/yes\"):\n    for file in f:\n        if '.jpg' in file:\n            paths.append(os.path.join(r,file))\nfor path in paths:\n    img = Image.open(path)\n    img = img.resize((224,224))\n    img = np.array(img)\n    if(img.shape == (224,224,3)):\n        data.append(img)\n        label.append(0)\n        input_path.append(os.path.join(\"Tumor\",\"Tumor\",path))\n        result.append(encoder.transform([[0]]).toarray())","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:31.390329Z","iopub.execute_input":"2022-09-09T15:19:31.390782Z","iopub.status.idle":"2022-09-09T15:19:32.352177Z","shell.execute_reply.started":"2022-09-09T15:19:31.390748Z","shell.execute_reply":"2022-09-09T15:19:32.351410Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"paths = []\nfor r,d,f in os.walk(r\"../input/brain-mri-images-for-brain-tumor-detection/no\"):\n    for file in f:\n        if '.jpg' in file:\n            paths.append(os.path.join(r,file))\nfor path in paths:\n    img = Image.open(path)\n    img = img.resize((224,224))\n    img = np.array(img)\n    if(img.shape == (224,224,3)):\n        data.append(img)\n        label.append(1)\n        input_path.append(os.path.join(\"No Tumor\",\"No Tumor\",path))\n        result.append(encoder.transform([[1]]).toarray())","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:32.354183Z","iopub.execute_input":"2022-09-09T15:19:32.354382Z","iopub.status.idle":"2022-09-09T15:19:33.031902Z","shell.execute_reply.started":"2022-09-09T15:19:32.354357Z","shell.execute_reply":"2022-09-09T15:19:33.031181Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"len(input_path)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:33.034039Z","iopub.execute_input":"2022-09-09T15:19:33.034242Z","iopub.status.idle":"2022-09-09T15:19:33.039744Z","shell.execute_reply.started":"2022-09-09T15:19:33.034217Z","shell.execute_reply":"2022-09-09T15:19:33.038973Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\ndf['images'] = input_path\ndf['label'] = label\ndf=df.sample(frac=1).reset_index(drop=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:33.041103Z","iopub.execute_input":"2022-09-09T15:19:33.042049Z","iopub.status.idle":"2022-09-09T15:19:33.070113Z","shell.execute_reply.started":"2022-09-09T15:19:33.041845Z","shell.execute_reply":"2022-09-09T15:19:33.069467Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"pd.unique(df['label'])","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:33.073127Z","iopub.execute_input":"2022-09-09T15:19:33.073715Z","iopub.status.idle":"2022-09-09T15:19:33.080402Z","shell.execute_reply.started":"2022-09-09T15:19:33.073678Z","shell.execute_reply":"2022-09-09T15:19:33.079587Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Count of each category**","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nsns.countplot(df['label'])","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:33.082295Z","iopub.execute_input":"2022-09-09T15:19:33.082553Z","iopub.status.idle":"2022-09-09T15:19:33.396009Z","shell.execute_reply.started":"2022-09-09T15:19:33.082520Z","shell.execute_reply":"2022-09-09T15:19:33.395263Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(np.array(result))","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:33.397388Z","iopub.execute_input":"2022-09-09T15:19:33.397642Z","iopub.status.idle":"2022-09-09T15:19:33.407721Z","shell.execute_reply.started":"2022-09-09T15:19:33.397608Z","shell.execute_reply":"2022-09-09T15:19:33.406889Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"result = np.array(result)\nresult = result.reshape(139,2)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:33.409386Z","iopub.execute_input":"2022-09-09T15:19:33.409688Z","iopub.status.idle":"2022-09-09T15:19:33.415219Z","shell.execute_reply.started":"2022-09-09T15:19:33.409653Z","shell.execute_reply":"2022-09-09T15:19:33.414480Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"result.shape","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:33.416317Z","iopub.execute_input":"2022-09-09T15:19:33.416622Z","iopub.status.idle":"2022-09-09T15:19:33.425441Z","shell.execute_reply.started":"2022-09-09T15:19:33.416588Z","shell.execute_reply":"2022-09-09T15:19:33.424591Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data = np.array(data)\n#data = data.reshape(139, 128, 128, 3)\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:33.427182Z","iopub.execute_input":"2022-09-09T15:19:33.427670Z","iopub.status.idle":"2022-09-09T15:19:33.444202Z","shell.execute_reply.started":"2022-09-09T15:19:33.427636Z","shell.execute_reply":"2022-09-09T15:19:33.443527Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**Displaying random images**","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nplt.figure(figsize=(10, 10))\nfor i in range(4):\n    plt.subplot(1, 4, i+1)\n    plt.imshow(data[i], cmap=\"gray\")\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:33.445526Z","iopub.execute_input":"2022-09-09T15:19:33.445761Z","iopub.status.idle":"2022-09-09T15:19:33.706414Z","shell.execute_reply.started":"2022-09-09T15:19:33.445730Z","shell.execute_reply":"2022-09-09T15:19:33.705656Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**Splitting data into training and testing data**","metadata":{}},{"cell_type":"code","source":"x_train , x_test , y_train , y_test = train_test_split(data , result , test_size = 0.25 , shuffle = True , random_state = 1)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:33.709631Z","iopub.execute_input":"2022-09-09T15:19:33.710120Z","iopub.status.idle":"2022-09-09T15:19:33.723566Z","shell.execute_reply.started":"2022-09-09T15:19:33.710081Z","shell.execute_reply":"2022-09-09T15:19:33.722898Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of an image in x_train : \",x_train[0].shape)\nprint(\"Shape of an image in x_test : \",x_test[0].shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:33.724994Z","iopub.execute_input":"2022-09-09T15:19:33.725265Z","iopub.status.idle":"2022-09-09T15:19:33.731425Z","shell.execute_reply.started":"2022-09-09T15:19:33.725232Z","shell.execute_reply":"2022-09-09T15:19:33.730590Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"x_train = np.array(x_train)\nx_test = np.array(x_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:33.732657Z","iopub.execute_input":"2022-09-09T15:19:33.733082Z","iopub.status.idle":"2022-09-09T15:19:33.747549Z","shell.execute_reply.started":"2022-09-09T15:19:33.733047Z","shell.execute_reply":"2022-09-09T15:19:33.746774Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(\"x_train Shape : \", x_train.shape) \nprint(\"x_test Shape : \", x_test.shape)\nprint(\"y_train Shape: \", y_train.shape) \nprint(\"y_test Shape: \", y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:33.748969Z","iopub.execute_input":"2022-09-09T15:19:33.749236Z","iopub.status.idle":"2022-09-09T15:19:33.756642Z","shell.execute_reply.started":"2022-09-09T15:19:33.749203Z","shell.execute_reply":"2022-09-09T15:19:33.755785Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"**Pre-Trained VGG16 model**","metadata":{}},{"cell_type":"code","source":"modelVGG = VGG16(include_top = False,weights = 'imagenet',classifier_activation = 'softmax',input_shape = (224, 224, 3))","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:33.758269Z","iopub.execute_input":"2022-09-09T15:19:33.758855Z","iopub.status.idle":"2022-09-09T15:19:37.502655Z","shell.execute_reply.started":"2022-09-09T15:19:33.758821Z","shell.execute_reply":"2022-09-09T15:19:37.501856Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for layer in modelVGG.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:37.503976Z","iopub.execute_input":"2022-09-09T15:19:37.504328Z","iopub.status.idle":"2022-09-09T15:19:37.509306Z","shell.execute_reply.started":"2022-09-09T15:19:37.504291Z","shell.execute_reply":"2022-09-09T15:19:37.508506Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"num_classes = 2\nfor (i,layer) in enumerate(modelVGG.layers):\n    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)\n    def lw(bottom_model,num_classes):\n        top_model = bottom_model.output\n        top_model = GlobalAveragePooling2D()(top_model)\n        top_model = Dense(1024,activation='relu')(top_model)\n        top_model = Dense(1024,activation='relu')(top_model)\n        top_model = Dense(512,activation='relu')(top_model)\n        top_model = Dense(2,activation='softmax')(top_model)\n        return top_model","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:37.510642Z","iopub.execute_input":"2022-09-09T15:19:37.511105Z","iopub.status.idle":"2022-09-09T15:19:37.527397Z","shell.execute_reply.started":"2022-09-09T15:19:37.511069Z","shell.execute_reply":"2022-09-09T15:19:37.526720Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\nfrom keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\nfrom keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:37.528821Z","iopub.execute_input":"2022-09-09T15:19:37.529160Z","iopub.status.idle":"2022-09-09T15:19:37.533836Z","shell.execute_reply.started":"2022-09-09T15:19:37.529126Z","shell.execute_reply":"2022-09-09T15:19:37.533083Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"num_classes = 2\nFC_Head = lw(modelVGG , num_classes)\nmodel = Model(inputs = modelVGG.input,outputs = FC_Head)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:37.535385Z","iopub.execute_input":"2022-09-09T15:19:37.535958Z","iopub.status.idle":"2022-09-09T15:19:37.574863Z","shell.execute_reply.started":"2022-09-09T15:19:37.535924Z","shell.execute_reply":"2022-09-09T15:19:37.574174Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"**Summary of the network layers**","metadata":{}},{"cell_type":"code","source":"print(model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:37.576265Z","iopub.execute_input":"2022-09-09T15:19:37.576514Z","iopub.status.idle":"2022-09-09T15:19:37.597415Z","shell.execute_reply.started":"2022-09-09T15:19:37.576482Z","shell.execute_reply":"2022-09-09T15:19:37.596741Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"**Fitting the Model**","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\nhistory = model.fit(x_train , y_train , epochs = 15 , validation_data = (x_test , y_test), verbose = 1 , initial_epoch = 0)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:37.599869Z","iopub.execute_input":"2022-09-09T15:19:37.600079Z","iopub.status.idle":"2022-09-09T15:19:53.468972Z","shell.execute_reply.started":"2022-09-09T15:19:37.600055Z","shell.execute_reply":"2022-09-09T15:19:53.468262Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:53.470749Z","iopub.execute_input":"2022-09-09T15:19:53.471040Z","iopub.status.idle":"2022-09-09T15:19:53.478782Z","shell.execute_reply.started":"2022-09-09T15:19:53.470980Z","shell.execute_reply":"2022-09-09T15:19:53.478056Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:53.480331Z","iopub.execute_input":"2022-09-09T15:19:53.481011Z","iopub.status.idle":"2022-09-09T15:19:53.705707Z","shell.execute_reply.started":"2022-09-09T15:19:53.480976Z","shell.execute_reply":"2022-09-09T15:19:53.705069Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"**Testing the model**","metadata":{}},{"cell_type":"code","source":"def names(number):\n    if number==0:\n        return \"It's a TUMOR\"\n    else:\n        return \"It's NOT a Tumor\"","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:53.707134Z","iopub.execute_input":"2022-09-09T15:19:53.707373Z","iopub.status.idle":"2022-09-09T15:19:53.711681Z","shell.execute_reply.started":"2022-09-09T15:19:53.707341Z","shell.execute_reply":"2022-09-09T15:19:53.710851Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"**Testing the model for a random image**","metadata":{}},{"cell_type":"code","source":"from matplotlib.pyplot import imshow\ndef Prediction(img):\n    x = np.array(img.resize((224,224)))\n    x = x.reshape(1,224,224,3)\n    res = model.predict_on_batch(x)\n    classification = np.where(res == np.amax(res))[1][0]\n    imshow(img)\n    print(str(res[0][classification]*100) + '% Confidence ' + names(classification))","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:30:23.407521Z","iopub.execute_input":"2022-09-09T15:30:23.407786Z","iopub.status.idle":"2022-09-09T15:30:23.414342Z","shell.execute_reply.started":"2022-09-09T15:30:23.407757Z","shell.execute_reply":"2022-09-09T15:30:23.413608Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"img = Image.open(r\"../input/brain-mri-images-for-brain-tumor-detection/yes/Y19.JPG\")\nPrediction(img)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:30:26.478455Z","iopub.execute_input":"2022-09-09T15:30:26.478731Z","iopub.status.idle":"2022-09-09T15:30:26.895220Z","shell.execute_reply.started":"2022-09-09T15:30:26.478701Z","shell.execute_reply":"2022-09-09T15:30:26.893219Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"img = Image.open(r\"../input/brain-mri-images-for-brain-tumor-detection/no/37 no.jpg\")\nPrediction(img)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:31:07.475007Z","iopub.execute_input":"2022-09-09T15:31:07.475733Z","iopub.status.idle":"2022-09-09T15:31:07.706552Z","shell.execute_reply.started":"2022-09-09T15:31:07.475695Z","shell.execute_reply":"2022-09-09T15:31:07.705833Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"img = Image.open(r\"../input/brain-mri-images-for-brain-tumor-detection/no/N26.JPG\")\nPrediction(img)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:32:05.808931Z","iopub.execute_input":"2022-09-09T15:32:05.809852Z","iopub.status.idle":"2022-09-09T15:32:06.036454Z","shell.execute_reply.started":"2022-09-09T15:32:05.809807Z","shell.execute_reply":"2022-09-09T15:32:06.035751Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"img = Image.open(r\"../input/brain-mri-images-for-brain-tumor-detection/yes/Y182.JPG\")\nPrediction(img)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:33:20.830069Z","iopub.execute_input":"2022-09-09T15:33:20.830336Z","iopub.status.idle":"2022-09-09T15:33:21.066560Z","shell.execute_reply.started":"2022-09-09T15:33:20.830307Z","shell.execute_reply":"2022-09-09T15:33:21.065758Z"},"trusted":true},"execution_count":41,"outputs":[]}]}